{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrNsx7SDpyoQ1lGowdqy4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh-keswani/pytorch-example-notebook/blob/main/15_PyTorchWithEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "822LnsL_xUVw"
      },
      "outputs": [],
      "source": [
        "# This notebook will not contain detailed implementation of some application\n",
        "# instead it is for how to exactly use Embedding layer which can be easily adapted based on the requirements\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMWithEmbedding(nn.Module):\n",
        "    def __init__(self, input_dimension, hidden_dimension, output_dimension, embedding_dimension):\n",
        "        super(LSTMWithEmbedding, self).__init__()\n",
        "\n",
        "        self.input_dimension = input_dimension\n",
        "        self.hidden_dimension = hidden_dimension\n",
        "        self.output_dimension = output_dimension\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "\n",
        "        # input_dimension can be size of  the vocab\n",
        "        self.embedding = nn.Embedding(input_dimension, embedding_dimension)\n",
        "        self.lstm = nn.LSTM(embedding_dimension, hidden_dimension, batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_dimension, output_dimension)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_dimension)\n",
        "        c0 = torch.zeros(1, x.size(0), self.hidden_dimension)\n",
        "        print(x.shape)\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        print(x.shape)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        print(out.shape)\n",
        "        # what you can do is, sometimes  instead of  using softmax layer\n",
        "        # we can directly use: out, _ = torch.max(out, 1) inorder to do max  pool\n",
        "\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        print(out.shape)\n",
        "        return out"
      ],
      "metadata": {
        "id": "cHxpZbWFxuWf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input parameters\n",
        "input_dimension = 10  # Vocabulary size\n",
        "hidden_dimension = 20  # Number of hidden units in LSTM\n",
        "output_dimension = 5   # Number of output classes\n",
        "embedding_dimension = 8  # Dimension of embeddings"
      ],
      "metadata": {
        "id": "t2yC-y0zzfTL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "model = LSTMWithEmbedding(input_dimension, hidden_dimension, output_dimension, embedding_dimension)"
      ],
      "metadata": {
        "id": "iAQ-uAJOzyPn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small valid sample input (batch_size, sequence_length).\n",
        "# Input to the Embedding layer should be integers or long only\n",
        "sample_input = torch.tensor([[1, 2, 3, 4], [2, 3, 4, 5]])  # Example batch of two sequences with 4 tokens each\n",
        "\n",
        "# Pass the sample input through the model\n",
        "output = model(sample_input)\n",
        "print(\"Output:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59LG5yFO0AV8",
        "outputId": "0b7296bb-20cf-4f11-8736-9e4cd8c30e7e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "torch.Size([2, 4, 8])\n",
            "torch.Size([2, 4, 20])\n",
            "torch.Size([2, 5])\n",
            "Output: tensor([[ 0.0540, -0.0490, -0.0998, -0.0354, -0.0661],\n",
            "        [ 0.1168, -0.0288, -0.1062, -0.0041, -0.0637]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Dae_tCU0NBp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}